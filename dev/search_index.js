var documenterSearchIndex = {"docs":
[{"location":"api/cells/#Cells","page":"Cells","title":"Cells","text":"","category":"section"},{"location":"api/cells/","page":"Cells","title":"Cells","text":"RANCell\nIndRNNCell\nLightRUCell\nLiGRUCell\nMGUCell\nNASCell\nRHNCell\nRHNCellUnit\nMUT1Cell\nMUT2Cell\nMUT3Cell\nSCRNCell","category":"page"},{"location":"api/cells/#RecurrentLayers.RANCell","page":"Cells","title":"RecurrentLayers.RANCell","text":"RANCell((in, out)::Pair;\n    kernel_init = glorot_uniform,\n    recurrent_kernel_init = glorot_uniform,\n    bias = true)\n\nThe RANCell, introduced in this paper,  is a recurrent cell layer which provides additional memory through the use of gates.\n\nand returns both ht anf ct.\n\nSee RAN for a layer that processes entire sequences.\n\nArguments\n\nin => out: Specifies the input and output dimensions of the layer.\ninit: Initialization function for the weight matrices, default is glorot_uniform.\nbias: Indicates if a bias term is included; the default is true.\n\nForward\n\nrancell(x, [h, c])\n\nThe forward pass takes the following arguments:\n\nx: Input to the cell, which can be a vector of size in or a matrix of size in x batch_size.\nh: The hidden state vector of the cell, sized out, or a matrix of size out x batch_size.\nc: The candidate state, sized out, or a matrix of size out x batch_size.\n\nIf not provided, both h and c default to vectors of zeros.\n\nExamples\n\nrancell = RANCell(3 => 5)\ninp = rand(Float32, 3)\n#initializing the hidden states, if we want to provide them\nstate = rand(Float32, 5)\nc_state = rand(Float32, 5)\n\n#result with default initialization of internal states\nresult = rancell(inp)\n#result with internal states provided\nresult_state = rancell(inp, (state, c_state))\n\n\n\n\n\n","category":"type"},{"location":"api/cells/#RecurrentLayers.IndRNNCell","page":"Cells","title":"RecurrentLayers.IndRNNCell","text":"function IndRNNCell((in, out)::Pair, σ=relu;\n    kernel_init = glorot_uniform,\n    recurrent_kernel_init = glorot_uniform,\n    bias = true)\n\n\n\n\n\n","category":"type"},{"location":"api/cells/#RecurrentLayers.LightRUCell","page":"Cells","title":"RecurrentLayers.LightRUCell","text":"LightRUCell((in, out)::Pair, σ=tanh;\n    kernel_init = glorot_uniform,\n    recurrent_kernel_init = glorot_uniform,\n    bias = true)\n\n\n\n\n\n","category":"type"},{"location":"api/cells/#RecurrentLayers.LiGRUCell","page":"Cells","title":"RecurrentLayers.LiGRUCell","text":"LiGRUCell((in, out)::Pair;\n    kernel_init = glorot_uniform,\n    recurrent_kernel_init = glorot_uniform,\n    bias = true)\n\n\n\n\n\n","category":"type"},{"location":"api/cells/#RecurrentLayers.MGUCell","page":"Cells","title":"RecurrentLayers.MGUCell","text":"MGUCell((in, out)::Pair;\n    kernel_init = glorot_uniform,\n    recurrent_kernel_init = glorot_uniform,\n    bias = true)\n\n\n\n\n\n","category":"type"},{"location":"api/cells/#RecurrentLayers.NASCell","page":"Cells","title":"RecurrentLayers.NASCell","text":"NASCell((in, out)::Pair;\n    kernel_init = glorot_uniform,\n    recurrent_kernel_init = glorot_uniform,\n    bias = true)\n\n\n\n\n\n","category":"type"},{"location":"api/cells/#RecurrentLayers.RHNCell","page":"Cells","title":"RecurrentLayers.RHNCell","text":"RHNCell((in, out), depth=3; couple_carry::Bool = true, cell_kwargs...)\n\n\n\n\n\n","category":"type"},{"location":"api/cells/#RecurrentLayers.RHNCellUnit","page":"Cells","title":"RecurrentLayers.RHNCellUnit","text":"RHNCellUnit((in, out)::Pair;\n    kernel_init = glorot_uniform,\n    bias = true)\n\n\n\n\n\n","category":"type"},{"location":"api/cells/#RecurrentLayers.MUT1Cell","page":"Cells","title":"RecurrentLayers.MUT1Cell","text":"MUT1Cell((in, out)::Pair;\n    kernel_init = glorot_uniform,\n    recurrent_kernel_init = glorot_uniform,\n    bias = true)\n\n\n\n\n\n","category":"type"},{"location":"api/cells/#RecurrentLayers.MUT2Cell","page":"Cells","title":"RecurrentLayers.MUT2Cell","text":"MUT2Cell((in, out)::Pair;\n    kernel_init = glorot_uniform,\n    recurrent_kernel_init = glorot_uniform,\n    bias = true)\n\n\n\n\n\n","category":"type"},{"location":"api/cells/#RecurrentLayers.MUT3Cell","page":"Cells","title":"RecurrentLayers.MUT3Cell","text":"MUT3Cell((in, out)::Pair;\n    kernel_init = glorot_uniform,\n    recurrent_kernel_init = glorot_uniform,\n    bias = true)\n\n\n\n\n\n","category":"type"},{"location":"api/cells/#RecurrentLayers.SCRNCell","page":"Cells","title":"RecurrentLayers.SCRNCell","text":"SCRNCell((in, out)::Pair;\n    kernel_init = glorot_uniform,\n    recurrent_kernel_init = glorot_uniform,\n    bias = true,\n    alpha = 0.0)\n\n\n\n\n\n","category":"type"},{"location":"api/wrappers/#Cell-wrappers","page":"Cell Wrappers","title":"Cell wrappers","text":"","category":"section"},{"location":"api/wrappers/","page":"Cell Wrappers","title":"Cell Wrappers","text":"RAN\nIndRNN\nLightRU\nLiGRU\nMGU\nNAS\nRHN\nMUT1\nMUT2\nMUT3\nSCRN","category":"page"},{"location":"api/wrappers/#RecurrentLayers.RAN","page":"Cell Wrappers","title":"RecurrentLayers.RAN","text":"RAN(in => out; kwargs...)\n\n\n\n\n\n","category":"type"},{"location":"api/wrappers/#RecurrentLayers.IndRNN","page":"Cell Wrappers","title":"RecurrentLayers.IndRNN","text":"IndRNN((in, out)::Pair, σ = tanh; kwargs...)\n\n\n\n\n\n","category":"type"},{"location":"api/wrappers/#RecurrentLayers.LightRU","page":"Cell Wrappers","title":"RecurrentLayers.LightRU","text":"LightRU((in, out)::Pair; kwargs...)\n\n\n\n\n\n","category":"type"},{"location":"api/wrappers/#RecurrentLayers.LiGRU","page":"Cell Wrappers","title":"RecurrentLayers.LiGRU","text":"LiGRU((in, out)::Pair; kwargs...)\n\n\n\n\n\n","category":"type"},{"location":"api/wrappers/#RecurrentLayers.MGU","page":"Cell Wrappers","title":"RecurrentLayers.MGU","text":"MGU((in, out)::Pair; kwargs...)\n\n\n\n\n\n","category":"type"},{"location":"api/wrappers/#RecurrentLayers.NAS","page":"Cell Wrappers","title":"RecurrentLayers.NAS","text":"NAS((in, out)::Pair; kwargs...)\n\n\n\n\n\n","category":"type"},{"location":"api/wrappers/#RecurrentLayers.RHN","page":"Cell Wrappers","title":"RecurrentLayers.RHN","text":"RHN((in, out)::Pair depth=3; kwargs...)\n\n\n\n\n\n","category":"type"},{"location":"api/wrappers/#RecurrentLayers.MUT1","page":"Cell Wrappers","title":"RecurrentLayers.MUT1","text":"MUT1((in, out)::Pair; kwargs...)\n\n\n\n\n\n","category":"type"},{"location":"api/wrappers/#RecurrentLayers.MUT2","page":"Cell Wrappers","title":"RecurrentLayers.MUT2","text":"MUT1Cell((in, out)::Pair; kwargs...)\n\n\n\n\n\n","category":"type"},{"location":"api/wrappers/#RecurrentLayers.MUT3","page":"Cell Wrappers","title":"RecurrentLayers.MUT3","text":"MUT3((in, out)::Pair; kwargs...)\n\n\n\n\n\n","category":"type"},{"location":"api/wrappers/#RecurrentLayers.SCRN","page":"Cell Wrappers","title":"RecurrentLayers.SCRN","text":"SCRN((in, out)::Pair; kwargs...)\n\n\n\n\n\n","category":"type"},{"location":"","page":"Home","title":"Home","text":"CurrentModule = RecurrentLayers","category":"page"},{"location":"","page":"Home","title":"Home","text":"<p align=\"center\">     <img width=\"400px\" src=\"assets/logo.png\"/> </p>","category":"page"},{"location":"#RecurrentLayers","page":"Home","title":"RecurrentLayers","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"RecurrentLayers.jl extends Flux.jl recurrent layers offering by providing implementations of bleeding edge recurrent layers not commonly available in base deep learning libraries. It is designed for a seamless integration with the larger Flux ecosystem, enabling researchers and practitioners to leverage the latest developments in recurrent neural networks.","category":"page"},{"location":"#Implemented-layers","page":"Home","title":"Implemented layers","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Minimal gated unit as  MGUCell arxiv\nLight gated recurrent unit as LiGRUCell arxiv\nIndependently recurrent neural networks as IndRNNCell arxiv\nRecurrent addictive networks as RANCell arxiv\nRecurrent highway network as `RHNCell arixv\nLight recurrent unit as LightRUCell pub\nNeural architecture search unit NASCell arxiv\nEvolving recurrent neural networks as MUT1Cell, MUT2Cell, MUT3Cell pub\nStructurally constrained recurrent neural network as SCRNCell arxiv","category":"page"},{"location":"#Contributing","page":"Home","title":"Contributing","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Contributions are always welcome! We look for specifically:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Recurrent cells you would like to see implemented \nBenchmarks\nAny bugs and mistakes of course!\nDocumentation, in any form: examples, how tos, docstrings  ","category":"page"}]
}
